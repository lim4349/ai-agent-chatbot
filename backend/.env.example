# === App ===
DEBUG=false
LOG_LEVEL=INFO
APP_NAME="AI Agent Chatbot"

# === LLM Provider ===
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4096
LLM_OPENAI_API_KEY=
LLM_ANTHROPIC_API_KEY=
LLM_BASE_URL=

# === Memory ===
# Options: in_memory (local dev), redis (production with Upstash)
MEMORY_BACKEND=in_memory
# Upstash Redis URL (production): rediss://default:<password>@<endpoint>.upstash.io:6379
# Local Redis: redis://localhost:6379/0
MEMORY_REDIS_URL=redis://localhost:6379/0
MEMORY_TTL_SECONDS=3600

# === RAG ===
RAG_COLLECTION_NAME=documents
RAG_EMBEDDING_PROVIDER=pinecone  # "openai" or "pinecone"
RAG_EMBEDDING_MODEL=multilingual-e5-large  # OpenAI: text-embedding-3-small, Pinecone: multilingual-e5-large
RAG_CHUNK_SIZE=500
RAG_CHUNK_OVERLAP=50
RAG_TOP_K=3
RAG_CHUNKING_STRATEGY=auto  # "auto", "default", "code", "tabular"

# Pinecone Configuration (for RAG vector storage)
# Get API key from https://app.pinecone.io
RAG_PINECONE_API_KEY=your_pinecone_api_key_here
RAG_PINECONE_INDEX_NAME=documents
RAG_PINECONE_NAMESPACE=default

# === MCP Servers (Model Context Protocol) ===
MCP_ENABLED=false
MCP_SERVERS_JSON=[]
MCP_DEFAULT_TIMEOUT=30
MCP_HEALTH_CHECK_ENABLED=true
# Example with servers:
# MCP_SERVERS_JSON=[{"name":"github","url":"http://localhost:3001","api_key":"ghp_xxx","tool_prefix":"github"},{"name":"filesystem","url":"http://localhost:3002","tool_prefix":"fs"}]

# === Tools ===
TOOLS_TAVILY_API_KEY=
TOOLS_CODE_EXECUTION_ENABLED=true
TOOLS_CODE_EXECUTION_TIMEOUT=10

# === Supabase Authentication ===
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_KEY=your_supabase_service_role_key_here
